{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1b27e0",
   "metadata": {},
   "source": [
    "# 0. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb229650",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data manipulation, statistics and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis, shapiro, ranksums, ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import scipy.signal as signal\n",
    "\n",
    "## model development and evaluation\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV,GridSearchCV, LeaveOneOut, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "## EEG analysis, DFA, feature selection\n",
    "import mne\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu\n",
    "import mrmr\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "## system operations\n",
    "import os\n",
    "import glob\n",
    "import openpyxl\n",
    "\n",
    "# %matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5922435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working paths\n",
    "PATH = r'C:\\Users\\nikol\\home\\master_thesis\\HRI'\n",
    "EEG_PATH = os.path.join(PATH,'Data', 'Cleaned EEG signals')\n",
    "DATA_PATH = os.path.join(PATH,'Data', 'Feature powers.xlsx')\n",
    "TARGET_PATH = os.path.join(PATH, 'Data', 'Target data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9f45d4",
   "metadata": {},
   "source": [
    "# 1. Load EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b53a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\10_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\11_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\12_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\13_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\14_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\15_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\16_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\17_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\18_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\19_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\20_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\21_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\22_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\23_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\24_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\25_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\26_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\27_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\28_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\29_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\30_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\31_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\32_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\33_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\34_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\35_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\36_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\37_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\38_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\39_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\40_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\41_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\42_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\43_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\44_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\45_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\46_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\47_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\48_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\49_final.fdt\n",
      "Reading C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Cleaned EEG signals\\9_final.fdt\n"
     ]
    }
   ],
   "source": [
    "robot_indx = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 28, 29, 32, 37, 46, 47, 49] #[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 28, 29, 32, 37, 46, 47, 49]\n",
    "display_indx = [19, 20, 24, 25, 26, 27, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48] #[19, 20, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48]\n",
    "\n",
    "\n",
    "robot_dict = {}\n",
    "display_dict = {}\n",
    "files = glob.glob(EEG_PATH + \"\\*.set\")\n",
    "\n",
    "for filePath in files:\n",
    "    fName = os.path.basename(filePath) #filename\n",
    "    _, ext = os.path.splitext(filePath) #extension (.set)\n",
    "    p = int(os.path.splitext(fName)[0].split('_')[0]) #split filenames into participant integers\n",
    "    \n",
    "    if p in robot_indx: # add each file with index in participant indeces to robot group\n",
    "        robot_dict[p] = mne.io.read_raw_eeglab(filePath, preload=False)\n",
    "    elif p in display_indx: # and display group\n",
    "        display_dict[p] = mne.io.read_raw_eeglab(filePath, preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839b9433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot-group dict: 20 participant(s)\n",
      "display-group dict: 21 participant(s)\n"
     ]
    }
   ],
   "source": [
    "# check participant count per condition\n",
    "n_robot = len(robot_dict)\n",
    "n_display = len(display_dict)\n",
    "\n",
    "print(\"robot-group dict:\", n_robot, 'participant(s)')\n",
    "print(\"display-group dict:\", n_display, 'participant(s)')\n",
    "\n",
    "# define dictionary to map 10-20 channel names to eeg sensor locations\n",
    "channel_dict = {}\n",
    "channels = ['E5', 'E10', 'E12', 'E20', 'E24', 'E28', 'E35', 'E39', 'E42', 'E50', 'E52', 'E60', 'E6', 'E18', 'E58', 'E34', 'E37','Cz']\n",
    "channel_names = ['Fp2', 'Fp1', 'F3', 'C3', 'T7', 'P3', 'O1', 'O2', 'P4', 'C4', 'T8', 'F4', 'Fz', 'F7', 'F8', 'Pz', 'Oz', 'Cz']\n",
    "\n",
    "x = 0\n",
    "for ch in channels:\n",
    "    channel_dict[ch] = channel_names[x]\n",
    "    x+=1\n",
    "\n",
    "# change channel names to 10-20 system\n",
    "for participant in robot_dict:\n",
    "    robot_dict[participant].pick_channels(channels)\n",
    "    robot_dict[participant].rename_channels(channel_dict)\n",
    "    \n",
    "for participant in display_dict:\n",
    "    display_dict[participant].pick_channels(channels)\n",
    "    display_dict[participant].rename_channels(channel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29531fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "children_indx = list(set(robot_indx + display_indx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efdb715",
   "metadata": {},
   "source": [
    "# 2. Extract DFA exponents from EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf25a29",
   "metadata": {},
   "source": [
    "generate a dictionary with EEG recordings of the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a54cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the the dictionaries with EEG recordings (the robot group EEG and the display group EEG)\n",
    "eeg_dict = {**robot_dict, **display_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e7b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set frequency and period for extracting EEG data\n",
    "sampling_freq = eeg_dict[9].info['sfreq']\n",
    "start_stop_seconds = np.array([0, 420])\n",
    "start_sample, stop_sample = (start_stop_seconds * sampling_freq).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78dcadd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp2', 'Fz', 'Fp1', 'F3', 'F7', 'C3', 'T7', 'P3', 'Pz', 'O1', 'Oz', 'O2', 'P4', 'C4', 'T8', 'F8', 'F4', 'Cz']"
     ]
    }
   ],
   "source": [
    "# print all of the 18 channels\n",
    "print(eeg_dict[9].ch_names, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201df53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the index of the EEG channel\n",
    "# change that index to calculate DFA for each channel\n",
    "channel_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d804a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionary that will contain the EEG data for all of the children and the specific channel\n",
    "eeg_data = {}\n",
    "\n",
    "\n",
    "for child in children_indx:\n",
    "      eeg_data[child] = eeg_dict[child][channel_index, start_sample:stop_sample][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d4c1b",
   "metadata": {},
   "source": [
    "extract the DFA exponents and save them in text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967fb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the epochs to divide the signal\n",
    "winSizes = fu.linRangeByStep(10, 420)\n",
    "revSeg = True\n",
    "polOrd = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52308c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(42)\n",
    "# create a list with DFA exponents for all of the children and the specific channel\n",
    "\n",
    "dfa_list = []\n",
    "\n",
    "for child in children_indx:\n",
    "    eeg_data[child] = fu.toAggregated(eeg_data[child])\n",
    "    pydfa = fathon.DFA(eeg_data[child])\n",
    "    n, F = pydfa.computeFlucVec(winSizes, revSeg=revSeg, polOrd=polOrd)\n",
    "    H, H_intercept = pydfa.fitFlucVec()\n",
    "    \n",
    "    dfa_list.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9148a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DFA exponents in a text file (for each children and for the specific channel)\n",
    "with open(f'./Data/{eeg_dict[9].ch_names[channel_index]}_dfa.txt', 'w') as file:\n",
    "    for exp in dfa_list:\n",
    "        file.write(f'{exp}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846052b",
   "metadata": {},
   "source": [
    "Then change the channel index and repeat the DFA calculations to obtain DFA exponents, for every children, for each of the 18 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7cfde",
   "metadata": {},
   "source": [
    "# 3. Prepare the spectral and spectral + dfa dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b94d6",
   "metadata": {},
   "source": [
    "get the subjects to remove from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec26e2c",
   "metadata": {},
   "source": [
    "### spectral dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5693be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\nikol\\home\\master_thesis\\HRI'\n",
    "EEG_PATH = os.path.join(PATH,'Data', 'Cleaned EEG signals')\n",
    "DATA_PATH = os.path.join(PATH,'Data', 'Feature powers.xlsx')\n",
    "TARGET_PATH = os.path.join(PATH, 'Data', 'Target data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e683d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\nikol\\home\\master_thesis\\HRI\\Data\\Feature powers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb60be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732eaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the pilot subjects\n",
    "\n",
    "df = df.drop(list(range(0,8)), axis=0)\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(['index'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the dataframe\n",
    "X_spec = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b04057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the indexes\n",
    "X_spec.reset_index(inplace = True)\n",
    "X_spec.drop(['index'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd71fb",
   "metadata": {},
   "source": [
    "### prepare dfa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "529e9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that will contain the DFA exponents\n",
    "dfa_data = dict((ch, []) for ch in robot_dict[9].ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee489a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10080/1028392368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtext_dfa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataString\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdfa_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_dfa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "# read each of the DFA text files\n",
    "for ch in robot_dict[9].ch_names:\n",
    "\n",
    "    data =  open(f'./Data/DFA_each_channel/{ch}_dfa.txt', 'r')\n",
    "\n",
    "    dataString = data.read()\n",
    "    text_dfa = dataString.split('\\n')\n",
    "                 \n",
    "    dfa_data[ch].append(text_dfa)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ee9d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in robot_dict[9].ch_names:\n",
    "    dfa_data[ch] = dfa_data[ch][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "087f919e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfa_data = pd.DataFrame(dfa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1acbe53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the DFA features into floats\n",
    "for ch in robot_dict[9].ch_names:\n",
    "    dfa_data[ch] = dfa_data[ch].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfe93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb834648",
   "metadata": {},
   "source": [
    "### remove the not-tested subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indexes of subjects to remove\n",
    "remove_list = [9, 18, 45, 46, 48, 42, 43, 44, 47]\n",
    "remove_index = []\n",
    "\n",
    "\n",
    "for num in remove_list:\n",
    "    remove_index.append(children_indx.index(num))\n",
    "\n",
    "print(remove_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06749cc4",
   "metadata": {},
   "source": [
    "remove not-tested subjects from spectral + dfa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_data.drop(remove_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the indexes\n",
    "dfa_data.reset_index(inplace = True)\n",
    "dfa_data.drop(['index'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5e5c7",
   "metadata": {},
   "source": [
    "remove not-tested subjects from spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a466d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.drop(remove_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ea5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the indexes\n",
    "X_spec.reset_index(inplace = True)\n",
    "X_spec.drop(['index'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbb927",
   "metadata": {},
   "source": [
    "### prepare target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = pd.read_csv(r'C:\\Users\\nikol\\home\\master_thesis\\HRI\\Processed data from Stephanie\\Target data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4750583",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score = np.mean(target_data['TOTAL CORRECT'])\n",
    "\n",
    "def classification_transf(row):\n",
    "    if row['TOTAL CORRECT'] > average_score:\n",
    "        return 1\n",
    "    elif row['TOTAL CORRECT'] < average_score:\n",
    "        return 0\n",
    "\n",
    "target_data['Successfull'] = target_data.apply(classification_transf, axis=1)\n",
    "\n",
    "y = target_data['Successfull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86450f94",
   "metadata": {},
   "source": [
    "# 4. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_viz = df.join(pd.Series(np.squeeze(y)).rename('Success'))\n",
    "dfa_viz = dfa_data.join(pd.Series(np.squeeze(y)).rename('Success'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecbff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "fig.tight_layout(pad=1, w_pad=2, h_pad=1.0)\n",
    "\n",
    "\n",
    "dfa_viz[dfa_viz['Success']== 0].iloc[:,:-1].boxplot(ax=axs.ravel()[0])\n",
    "dfa_viz[dfa_viz['Success']== 1].iloc[:,:-1].boxplot(ax=axs.ravel()[1])\n",
    "\n",
    "axs.ravel()[0].set_title('Bad learners')\n",
    "axs.ravel()[1].set_title('Good learners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf505e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "fig, axs = plt.subplots(6, 3, figsize=(20,15))\n",
    "fig.tight_layout(pad=1, w_pad=2, h_pad=1.0)\n",
    "dfa_ch = robot_dict[9].ch_names\n",
    "\n",
    "for ch, ax in zip(dfa_ch, axs.ravel()):\n",
    "    ax.boxplot([dfa_viz[dfa_viz['Success']== 0].iloc[:,:-1][f'{ch}'],dfa_viz[dfa_viz['Success']== 1].iloc[:,:-1][f'{ch}']])\n",
    "    ax.set_xticklabels(['Bad learners', 'Good learners'])\n",
    "    ax.set_title(f'{ch}')\n",
    "    ax.grid(visible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b281398",
   "metadata": {},
   "source": [
    "# 5. Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428fa761",
   "metadata": {},
   "source": [
    "#### spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(spec_viz[spec_viz['Success']==0]['Alpha_Fp2'], spec_viz[spec_viz['Success']==1]['Alpha_Fp2'], alternative='less').pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapiro-Wilk test \n",
    "for spec in ['Alpha', 'Beta', 'Theta']:\n",
    "    for ch in robot_dict[9].ch_names:\n",
    "        print(f'{spec}_{ch}:', shapiro(spec_viz[f'{spec}_{ch}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d46f1",
   "metadata": {},
   "source": [
    "parametric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d797102",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_pvalues = []\n",
    "for spec in ['Alpha', 'Beta', 'Theta']:\n",
    "    for ch in robot_dict[9].ch_names:\n",
    "    \n",
    "        print(f'{spec}_{ch} feature: ',ttest_ind(spec_viz[spec_viz['Success']==0][f'{spec}' + '_' + f'{ch}'], spec_viz[spec_viz['Success']==1][f'{spec}' + '_' + f'{ch}'], alternative='less').pvalue)\n",
    "        spec_pvalues.append(ttest_ind(spec_viz[spec_viz['Success']==0][f'{spec}' + '_' + f'{ch}'], spec_viz[spec_viz['Success']==1][f'{spec}' + '_' + f'{ch}'], alternative='less').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac43e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "rejected_spec, p_adj_spec, _, alpha_corrected_spec = multipletests(spec_pvalues, \n",
    "                                                              alpha=alpha,\n",
    "                                                              method='bonferroni', \n",
    "                                                              is_sorted=False, \n",
    "                                                              returnsorted=False)\n",
    "\n",
    "print(np.sum(rejected_spec))\n",
    "\n",
    "print(alpha_corrected_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6203c",
   "metadata": {},
   "source": [
    "non-parametric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_pvalues = []\n",
    "for spec in ['Alpha', 'Beta', 'Theta']:\n",
    "    for ch in robot_dict[9].ch_names:\n",
    "    \n",
    "        print(f'{spec}_{ch} feature: ',ranksums(spec_viz[spec_viz['Success']==0][f'{spec}' + '_' + f'{ch}'], spec_viz[spec_viz['Success']==1][f'{spec}' + '_' + f'{ch}'], alternative='greater').pvalue< 0.05)\n",
    "        spec_pvalues.append(ranksums(spec_viz[spec_viz['Success']==0][f'{spec}' + '_' + f'{ch}'], spec_viz[spec_viz['Success']==1][f'{spec}' + '_' + f'{ch}'], alternative='greater').pvalue)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335337cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "rejected_spec, p_adj_spec, _, alpha_corrected_spec = multipletests(spec_pvalues, \n",
    "                                                              alpha=alpha,\n",
    "                                                              method='bonferroni', \n",
    "                                                              is_sorted=False, \n",
    "                                                              returnsorted=False)\n",
    "\n",
    "print(np.sum(rejected_spec))\n",
    "\n",
    "print(alpha_corrected_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88342a6",
   "metadata": {},
   "source": [
    "#### dfa + spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for normality\n",
    "\n",
    "# skewness (-2, +2) and kurtosis(-7, +7)\n",
    "\n",
    "print('Skewness in {ch}: ', skew(dfa_viz.Fp2))\n",
    "print('Kurtosis:', kurtosis(dfa_viz.Fp2))\n",
    "\n",
    "\n",
    "\n",
    "#Shapiro-Wilk test \n",
    "for ch in robot_dict[9].ch_names:\n",
    "    print(f'{ch}:', shapiro(dfa_viz[f'{ch}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test for the means of two independent samples\n",
    "dfa_pvalues = []\n",
    "\n",
    "for ch in robot_dict[9].ch_names:\n",
    "    \n",
    "    print(f'{ch} channel: ',ttest_ind(dfa_viz[dfa_viz['Success']==0][f'{ch}'], dfa_viz[dfa_viz['Success']==1][f'{ch}'], alternative='less'))\n",
    "    dfa_pvalues.append(ttest_ind(dfa_viz[dfa_viz['Success']==0][f'{ch}'], dfa_viz[dfa_viz['Success']==1][f'{ch}'], alternative='less').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_dfa, p_adj_dfa, _, alpha_corrected_dfa = multipletests(dfa_pvalues, \n",
    "                                                              alpha=alpha,\n",
    "                                                              method='bonferroni', \n",
    "                                                              is_sorted=False, \n",
    "                                                              returnsorted=False)\n",
    "\n",
    "print(np.sum(rejected_dfa))\n",
    "\n",
    "print(alpha_corrected_dfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60516127",
   "metadata": {},
   "source": [
    "# 6. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a8e5d",
   "metadata": {},
   "source": [
    "#### minimum Redundancy - Maximum Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed22e0",
   "metadata": {},
   "source": [
    "spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_spec = mrmr_classif(X=X_spec, y=y, K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec = X_spec[selected_features_spec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360ea76",
   "metadata": {},
   "source": [
    "dfa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_dfa = mrmr_classif(X=dfa_data, y=y, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_data = dfa_data[selected_features_dfa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc217f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff964171",
   "metadata": {},
   "source": [
    "# 7. Develop the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3db68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = { 'C':[10.0, 100.0,1000.0, 10000.0, 100000.0],\n",
    "              'kernel':['rbf','poly'],\n",
    "              'degree':[1,2,3,4],\n",
    "              'gamma': [10.0, 100.0,300]}\n",
    "\n",
    "\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "\n",
    "param_grid_knn = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features_spec = scaler.fit_transform(X_spec.values)\n",
    "X_spec_norm = pd.DataFrame(scaled_features_spec, index=X_spec.index, columns=X_spec.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d66ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_dfa = scaler.fit_transform(X_dfa.values)\n",
    "X_dfa_norm = pd.DataFrame(scaled_features_dfa, index=X_dfa.index, columns=X_dfa.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6524da3",
   "metadata": {},
   "source": [
    "## spectral data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00948bb1",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_spec = GridSearchCV(SVC(random_state=42),\n",
    "                                 param_grid_svc,\n",
    "                                 cv=LeaveOneOut(), \n",
    "                                 n_jobs=-1)\n",
    "svc_spec.fit(X_spec_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_spec.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a8a0a",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec = GridSearchCV(KNeighborsClassifier(),\n",
    "                                 param_grid_knn,\n",
    "                                 cv=LeaveOneOut(), \n",
    "                                 n_jobs=-1)\n",
    "knn_spec.fit(X_spec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990aed88",
   "metadata": {},
   "source": [
    "## spectral + DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dfa = df.join(dfa_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf54c8",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_dfa = GridSearchCV(SVC(random_state=42),\n",
    "                                 param_grid_svc,\n",
    "                                 cv=LeaveOneOut(), \n",
    "                                 n_jobs=-1)\n",
    "svc_dfa.fit(X_dfa, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_dfa.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e26b23",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dfa = GridSearchCV(KNeighborsClassifier(),\n",
    "                                 param_grid_knn,\n",
    "                                 cv=LeaveOneOut(), \n",
    "                                 n_jobs=-1)\n",
    "knn_dfa.fit(X_dfa_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe60134",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dfa.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecaff7d",
   "metadata": {},
   "source": [
    "# 8. Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that compares the LOO perfromance of a set of predetrmined models \n",
    "def cv_comparison(models, X, y):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    loo = LeaveOneOut()\n",
    "    cv_metrics = pd.DataFrame()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    random.seed(42)\n",
    "\n",
    "    for model in models:\n",
    "        for i, j in loo.split(X):\n",
    "            X_train, X_test = X.iloc[i,:], X.iloc[j, :]\n",
    "            y_train, y_test = y[i], y[j]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_hat = model.predict(X_test)\n",
    "            y_true.append(y_test[0])\n",
    "            y_pred.append(y_hat[0])\n",
    "            \n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            recall = recall_score(y_true, y_pred)\n",
    "            precision = precision_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "            cv_metrics[str(model)] = [recall, precision, f1, accuracy]\n",
    "    cv_metrics.index = ['Recall', 'Precision', 'F1-score', 'Accuracy']\n",
    "    return cv_metrics, recall, precision, f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d24f65",
   "metadata": {},
   "source": [
    "## spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SVM hyperparameters: {svc_spec.best_params_}')\n",
    "print(f'KNN hyperparameters: {knn_spec.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_spec_model = SVC(C=100,\n",
    "                    degree=1,\n",
    "                    gamma=300,\n",
    "                    kernel='rbf', random_state=42)\n",
    "\n",
    "knn_spec_model = KNeighborsClassifier(leaf_size=1,\n",
    "                                     n_neighbors = 9,\n",
    "                                     p=2)\n",
    "\n",
    "zeroR_spec = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "models = [svm_spec_model, knn_spec_model, zeroR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_spec, recall, precision, f1, accuracy = cv_comparison(models, X_spec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7137b",
   "metadata": {},
   "source": [
    "### DFA + Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d367217",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'SVM hyperparameters: {svc_dfa.best_params_}')\n",
    "print(f'KNN hyperparameters: {knn_dfa.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_dfa_model = SVC(C=10,\n",
    "                    degree=1,\n",
    "                    gamma=10,\n",
    "                    kernel='poly')\n",
    "\n",
    "knn_dfa_model = KNeighborsClassifier(leaf_size=1,\n",
    "                                     n_neighbors = 7,\n",
    "                                     p=2)\n",
    "\n",
    "zeroR_dfa = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "models = [svm_dfa_model, knn_dfa_model, zeroR_dfa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dfa, recall, precision, f1, accuracy = cv_comparison(models, X_dfa, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dfa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
